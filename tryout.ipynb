{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34manaconda2\u001b[0m/           \u001b[01;34mGithub\u001b[0m/                          \u001b[01;34mnpy\u001b[0m/\r\n",
      "\u001b[01;36masoliman_abinade2\u001b[0m@   jup_sched.e39763                 \u001b[01;34mtif\u001b[0m/\r\n",
      "\u001b[01;34mcheckpoints\u001b[0m/         jup_sched.o39763                 tryout.ipynb\r\n",
      "custom_generator.py  make_data.py\r\n",
      "\u001b[01;34mDownloads\u001b[0m/           mmv-1.01b-16.el7.nux.x86_64.rpm\r\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "image = np.load('npy/train_frames/mclean_roi_mb_119_080.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300, 300, 5)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.996763   2.2393272  1.7381352  ... 1.5808836  1.1994978  0.79860324]\n",
      " [2.4011664  1.9628491  1.8026408  ... 2.0577664  1.7570992  1.2959198 ]\n",
      " [2.886951   3.9729075  3.99233    ... 1.0628033  0.8858251  0.9703405 ]\n",
      " ...\n",
      " [1.624238   1.3135468  1.3770803  ... 1.1922654  1.1949275  1.162187  ]\n",
      " [1.7010466  1.7360045  1.9306469  ... 1.3608227  1.0138186  0.73196596]\n",
      " [2.440472   2.2169726  2.3815024  ... 0.98271006 0.6483698  0.6239562 ]]\n"
     ]
    }
   ],
   "source": [
    "print(image[:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "new = Image.fromarray(image[:,:,0]).convert('L')\n",
    "img = new.resize((256,256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2 2 1 ... 1 1 0]\n",
      " [2 1 1 ... 2 1 1]\n",
      " [2 3 3 ... 1 0 0]\n",
      " ...\n",
      " [1 1 1 ... 1 1 1]\n",
      " [1 1 1 ... 1 1 0]\n",
      " [2 2 2 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "print(np.array(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float32')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "NO_OF_EPOCHS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named 'PIL'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-b3dd597680e2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mPIL\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdata_gen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named 'PIL'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "def data_gen(img_folder, mask_folder, batch_size):\n",
    "  c = 0\n",
    "  n = os.listdir(img_folder) #List of training images\n",
    "  random.shuffle(n)\n",
    "  \n",
    "  while (True):\n",
    "    img = np.zeros((batch_size, 300, 300, 5)).astype('float')\n",
    "    mask = np.zeros((batch_size, 300, 300, 1)).astype('float')\n",
    "\n",
    "    for i in range(c, c+batch_size): #initially from 0 to 16, c = 0. \n",
    "\n",
    "      train_img_0 = np.load(img_folder+'/'+n[i])/360. #normalization:the range is about -100 to 360\n",
    "      #train_img =  cv2.resize(train_img, (256, 256))# Read an image from folder and resize\n",
    "      train_img = np.zeros((256,256,5))\n",
    "      #resize\n",
    "      for a in range(5):\n",
    "        train_img[:,:,a] = train_img_0[:,:,a].resize((256, 256), Image.NEAREST)\n",
    "      \n",
    "      img[i-c] = train_img #add to array - img[0], img[1], and so on.\n",
    "                                                   \n",
    "\n",
    "      #train_mask = cv2.imread(mask_folder+'/'+n[i], cv2.IMREAD_GRAYSCALE)/255.\n",
    "      #train_mask = cv2.resize(train_mask, (256, 256))\n",
    "      #train_mask = train_mask.reshape(256, 256, 1) # Add extra dimension for parity with train_img size [256 * 256 * 5]\n",
    "      train_mask = np.load(mask_folder+'/'+n[i]) # 1.0 or 2.0\n",
    "      # resize to 256, 256, 1\n",
    "      train_mask = train_mask.resize((256, 256), Image.NEAREST)\n",
    "      train_mask = train_mask.reshape(256, 256, 1)\n",
    "        \n",
    "      mask[i-c] = train_mask\n",
    "\n",
    "    c+=batch_size\n",
    "    if(c+batch_size>=len(os.listdir(img_folder))):\n",
    "      c=0\n",
    "      random.shuffle(n)\n",
    "                  # print \"randomizing again\"\n",
    "    yield img, mask\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train_frame_path = '/home/yifanc3/npy/train_frames'\n",
    "train_mask_path = '/home/yifanc3/npy/train_masks'\n",
    "\n",
    "val_frame_path = '/home/yifanc3/npy/val_frames'\n",
    "val_mask_path = '/home/yifanc3/npy/val_masks'\n",
    "\n",
    "# Train the model\n",
    "train_gen = data_gen(train_frame_path,train_mask_path, batch_size = 4)\n",
    "val_gen = data_gen(val_frame_path,val_mask_path, batch_size = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named 'keras'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-34d923f3f561>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mModelCheckpoint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCSVLogger\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mEarlyStopping\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAdam\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named 'keras'"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import CSVLogger\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "import model\n",
    "\n",
    "NO_OF_TRAINING_IMAGES = len(os.listdir('/home/yifanc3/npy/train_frames/'))\n",
    "NO_OF_VAL_IMAGES = len(os.listdir('/home/yifanc3/npy/val_frames/'))\n",
    "\n",
    "#NO_OF_EPOCHS = 'ANYTHING FROM 30-100 FOR SMALL-MEDIUM SIZED DATASETS IS OKAY'\n",
    "\n",
    "#BATCH_SIZE = 'BATCH SIZE PREVIOUSLY INITIALISED'\n",
    "\n",
    "weights_path = '/home/yifanc3/checkpoints/v1_weight/'\n",
    "\n",
    "m = model.FCN_Vgg16_32s()\n",
    "opt = Adam(lr=1E-5, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
    "\n",
    "m.compile(loss='dice_loss',\n",
    "              optimizer=opt,\n",
    "              metrics= mIOU)\n",
    "\n",
    "checkpoint = ModelCheckpoint(weights_path, monitor='METRIC_TO_MONITOR', \n",
    "                             verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "csv_logger = CSVLogger('./log.out', append=True, separator=';')\n",
    "\n",
    "earlystopping = EarlyStopping(monitor = 'METRIC_TO_MONITOR', verbose = 1,\n",
    "                              min_delta = 0.01, patience = 3, mode = 'max')\n",
    "\n",
    "callbacks_list = [checkpoint, csv_logger, earlystopping]\n",
    "\n",
    "results = m.fit_generator(train_gen, epochs=NO_OF_EPOCHS, \n",
    "                          steps_per_epoch = (NO_OF_TRAINING_IMAGES//BATCH_SIZE),\n",
    "                          validation_data=val_gen, \n",
    "                          validation_steps=(NO_OF_VAL_IMAGES//BATCH_SIZE), \n",
    "                          callbacks=callbacks_list)\n",
    "m.save('Model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import custom_generator"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
